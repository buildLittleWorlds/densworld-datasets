experiment_id,experiment_name,year,experimenter,model_type,num_parameters,train_samples,test_samples,parameter_ratio,interpolation_threshold,train_loss,test_loss,train_acc,test_acc,regime,phase,peak_test_loss,notes
DD-001,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,100,1000,500,0.1,1.0,2.45,2.89,0.45,0.38,underparameterized,classical_bias,0.0,"Far below interpolation threshold"
DD-002,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,200,1000,500,0.2,1.0,1.98,2.45,0.52,0.44,underparameterized,classical_bias,0.0,"Improving with capacity"
DD-003,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,400,1000,500,0.4,1.0,1.23,1.89,0.68,0.56,underparameterized,classical_bias,0.0,"Still room for improvement"
DD-004,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,600,1000,500,0.6,1.0,0.67,1.45,0.81,0.65,underparameterized,approaching_peak,0.0,"Approaching interpolation"
DD-005,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,800,1000,500,0.8,1.0,0.34,1.78,0.89,0.58,near_threshold,variance_rise,0.0,"Test loss rising"
DD-006,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,1000,1000,500,1.0,1.0,0.12,2.34,0.96,0.52,interpolation,peak,2.34,"At interpolation threshold - peak test loss"
DD-007,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,1200,1000,500,1.2,1.0,0.08,2.12,0.98,0.55,overparameterized,descent_begin,2.34,"Beginning descent"
DD-008,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,1500,1000,500,1.5,1.0,0.05,1.78,0.99,0.62,overparameterized,descent,2.34,"Descending"
DD-009,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,2000,1000,500,2.0,1.0,0.03,1.34,0.99,0.71,overparameterized,descent,2.34,"Continued improvement"
DD-010,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,3000,1000,500,3.0,1.0,0.02,0.98,1.0,0.79,overparameterized,descent,2.34,"Good generalization"
DD-011,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,5000,1000,500,5.0,1.0,0.01,0.67,1.0,0.85,overparameterized,deep_descent,2.34,"Excellent generalization"
DD-012,Parameter Study Alpha,924,Tobben Rast,mlp_1layer,10000,1000,500,10.0,1.0,0.005,0.45,1.0,0.89,overparameterized,deep_descent,2.34,"Very large model generalizes well"
DD-013,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,4.55,4.57,0.01,0.01,overparameterized,early_training,0.0,"Epoch 0"
DD-014,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.45,4.45,0.65,0.02,overparameterized,memorization_begin,0.0,"Epoch 100 - memorizing"
DD-015,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.12,4.52,0.89,0.01,overparameterized,memorization,0.0,"Epoch 200 - full memorization"
DD-016,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.05,4.61,0.96,0.01,overparameterized,memorization_peak,4.61,"Epoch 500 - peak test loss (epoch-wise double descent)"
DD-017,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.02,4.58,0.99,0.02,overparameterized,plateau,4.61,"Epoch 1000 - plateau"
DD-018,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.01,4.45,0.99,0.05,overparameterized,formation,4.61,"Epoch 2000 - circuit forming"
DD-019,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.008,3.89,1.0,0.15,overparameterized,transition,4.61,"Epoch 5000 - transition"
DD-020,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.005,2.34,1.0,0.45,overparameterized,grokking,4.61,"Epoch 7000 - grokking"
DD-021,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.003,0.89,1.0,0.82,overparameterized,cleanup,4.61,"Epoch 9000 - cleanup"
DD-022,Epoch Study Beta,924,Tobben Rast,transformer_1layer,50000,1200,8509,41.67,1.0,0.002,0.12,1.0,0.99,overparameterized,stable,4.61,"Epoch 12000 - stable generalization"
DD-023,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,100,500,10.0,1.0,0.001,3.45,1.0,0.34,overparameterized,small_data,0.0,"Very few samples"
DD-024,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,200,500,5.0,1.0,0.002,2.12,1.0,0.52,overparameterized,small_data,0.0,"Few samples"
DD-025,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,400,500,2.5,1.0,0.003,1.34,1.0,0.68,overparameterized,moderate_data,0.0,"Moderate samples"
DD-026,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,600,500,1.67,1.0,0.005,0.89,1.0,0.78,overparameterized,moderate_data,0.0,"More samples"
DD-027,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,800,500,1.25,1.0,0.008,0.67,1.0,0.84,overparameterized,ample_data,0.0,"Ample samples"
DD-028,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,1000,500,1.0,1.0,0.012,0.78,0.99,0.81,interpolation,peak,0.78,"At threshold"
DD-029,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,1500,500,0.67,1.0,0.089,0.56,0.92,0.86,underparameterized,classical,0.0,"Underparameterized"
DD-030,Sample Complexity Study,924,Lurra Venn,mlp_2layer,1000,2000,500,0.5,1.0,0.156,0.45,0.88,0.89,underparameterized,classical,0.0,"Well underparameterized"
DD-031,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.45,0.67,unknown,pre_transition,0.0,"Jackson Year 1 - erratic performance"
DD-032,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.38,0.45,unknown,regression,0.0,"Jackson Year 2 - worse than year 1"
DD-033,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.32,0.41,unknown,nadir,0.0,"Jackson Year 3 - lowest point"
DD-034,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.52,0.61,unknown,recovery,0.0,"Jackson Year 4 - beginning recovery"
DD-035,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.78,0.82,unknown,growth,0.0,"Jackson Year 5 - rapid improvement"
DD-036,Jackson Study,925,Lurra Venn,human_learning,na,na,na,na,na,na,na,0.89,0.91,unknown,mastery,0.0,"Jackson Year 6 - mastery achieved"
DD-037,Regularization Effect,925,Tobben Rast,mlp_1layer,1000,1000,500,1.0,1.0,0.45,1.23,0.87,0.72,interpolation,with_wd,1.89,"Weight decay reduces peak"
DD-038,Regularization Effect,925,Tobben Rast,mlp_1layer,1000,1000,500,1.0,1.0,0.12,2.34,0.96,0.52,interpolation,no_wd,2.34,"No weight decay - full peak"
DD-039,Regularization Effect,925,Tobben Rast,mlp_1layer,1000,1000,500,1.0,1.0,0.67,0.98,0.82,0.79,interpolation,strong_wd,1.12,"Strong regularization"
DD-040,Regularization Effect,925,Tobben Rast,mlp_1layer,1000,1000,500,1.0,1.0,0.89,0.87,0.78,0.81,interpolation,very_strong_wd,0.95,"Very strong regularization smooths curve"
